{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build_GNN_2: message passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from MPNN_featurize import featurize\n",
    "from build_GNN_1 import ProteinFeatures, gather_edges, PositionalEncodings\n",
    "\n",
    "batch = [\n",
    "    {\n",
    "        'seq_chain_A': 'MKLVFLVLLVFVQGF',\n",
    "        'coords_chain_A': {'N_chain_A': np.random.rand(15, 3), 'CA_chain_A': np.random.rand(15, 3), 'C_chain_A': np.random.rand(15, 3), 'O_chain_A': np.random.rand(15, 3)},\n",
    "        'seq_chain_B': 'MSVKVEEVG',\n",
    "        'coords_chain_B': {'N_chain_B': np.random.rand(9, 3), 'CA_chain_B': np.random.rand(9, 3), 'C_chain_B': np.random.rand(9, 3), 'O_chain_B': np.random.rand(9, 3)},\n",
    "        'seq_chain_C': 'ATCGATCGATCGATCG',\n",
    "        'coords_chain_C': {'N_chain_C': np.random.rand(16, 3), 'CA_chain_C': np.random.rand(16, 3), 'C_chain_C': np.random.rand(16, 3), 'O_chain_C': np.random.rand(16, 3)},\n",
    "        'masked_list': ['A', 'B'],\n",
    "        'visible_list': ['C'],\n",
    "        'num_of_chains': 3,\n",
    "        'seq': 'MKLVFLVLLVFVQGF'+ 'MSVKVEEVG' + 'ATCGATCGATCGATCG'\n",
    "    },\n",
    "      {\n",
    "        'seq_chain_X': 'ACDEFGHIKLMNPQRSTVWY',\n",
    "        'coords_chain_X': {'N_chain_X': np.random.rand(20, 3), 'CA_chain_X': np.random.rand(20, 3), 'C_chain_X': np.random.rand(20, 3), 'O_chain_X': np.random.rand(20, 3)},\n",
    "        'seq_chain_Y': 'ACCDEFGHILKLM',\n",
    "        'coords_chain_Y': {'N_chain_Y': np.random.rand(13, 3), 'CA_chain_Y': np.random.rand(13, 3), 'C_chain_Y': np.random.rand(13, 3), 'O_chain_Y': np.random.rand(13, 3)},\n",
    "        'seq_chain_Z': 'LKLMNRPQRST',\n",
    "        'coords_chain_Z': {'N_chain_Z': np.random.rand(11, 3), 'CA_chain_Z': np.random.rand(11, 3), 'C_chain_Z': np.random.rand(11, 3), 'O_chain_Z': np.random.rand(11, 3)},\n",
    "        'masked_list': ['X', 'Y'],\n",
    "        'visible_list': ['Z'],\n",
    "        'num_of_chains': 3,\n",
    "        'seq': 'ACDEFGHIKLMNPQRSTVWY'+'ACCDEFGHILKLM'+'LKLMNRPQRST'\n",
    "\n",
    "    }\n",
    "]\n",
    "device='cuda'\n",
    "X, S, mask, lengths, chain_M, residue_idx, mask_self, chain_encoding_all = featurize(batch, device)\n",
    "demo = ProteinFeatures(\n",
    "    edge_features=16, node_features=16, num_positional_embeddings=16,\n",
    "    num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16\n",
    ").to(device)\n",
    "E, E_idx=demo.forward(X,chain_M, residue_idx, chain_encoding_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 44, 30, 16])\n",
      "torch.Size([2, 44, 30])\n",
      "torch.Size([2, 44, 30])\n"
     ]
    }
   ],
   "source": [
    "# initialize h_V with zero match h_E dim\n",
    "import torch\n",
    "h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device) #[N,L,C]\n",
    "# MLP of h_E, we omit it here\n",
    "edge_features=E.shape[-1]\n",
    "hidden_dim=16\n",
    "W_e = torch.nn.Linear(edge_features, hidden_dim, bias=True).to(device)\n",
    "h_E = W_e(E)\n",
    "print(h_E.shape)\n",
    "\n",
    "# mask  [B, L]\n",
    "def gather_nodes(nodes, neighbor_idx):\n",
    "    # Features [B,L,C] at Neighbor indices [B,L,K] => [B,N,K,C]\n",
    "    # Flatten and expand indices per batch [B,L,K] => [B,LK] => [B,NK,C]\n",
    "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1)) # [B, LK]\n",
    "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2)) #[B,Lk,1]->[b,lk,c]\n",
    "    # Gather and re-pack\n",
    "    # nodes [B,L,L,1]\n",
    "    neighbor_features = torch.gather(nodes, 1, neighbors_flat) # [b, lk, C]\n",
    "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1]) # B, L, K, C\n",
    "    return neighbor_features\n",
    "\n",
    "# Encoder is unmasked self-attention\n",
    "mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1) # [B,L,K]\n",
    "print(mask_attend.shape)\n",
    "mask_attend = mask.unsqueeze(-1) * mask_attend # [B, L, 1]*[B, L, K] # make sure only true residue has neighours padding mask\n",
    "print(mask_attend.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN ENCODE LAYER\n",
    "update h_E, h_v using GNN\n",
    "Here is how they are updated:\n",
    "message = Mean_Aggreg(3layerMLP(concat(edge feature, neighbours node features))\n",
    "h_V =  Norm(h_V+mesage))\n",
    "h_v = Norm( h_V+ MLP(h_V))\n",
    "\n",
    "Then edge feature h_E is updated based on updated h_V\n",
    "message = 3layerMLP(concat(edge feature, neighbours node features)\n",
    "h_E = Norm(h_E + message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Code\n",
    "import torch.nn as nn\n",
    "def gather_nodes(nodes, neighbor_idx):\n",
    "    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n",
    "    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n",
    "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n",
    "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
    "    # Gather and re-pack\n",
    "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
    "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
    "    return neighbor_features  # [B, N, K, C]\n",
    "\n",
    "def gather_nodes_t(nodes, neighbor_idx):\n",
    "    # Features [B,N,C] at Neighbor index [B,K] => Neighbor features[B,K,C]\n",
    "    idx_flat = neighbor_idx.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
    "    neighbor_features = torch.gather(nodes, 1, idx_flat)\n",
    "    return neighbor_features\n",
    "\n",
    "def cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n",
    "    h_nodes = gather_nodes(h_nodes, E_idx)  # [B,L,K,C] \n",
    "    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n",
    "    return h_nn\n",
    "\n",
    "# not sure the meaning of positionWise but it is a simple 2 layer MLP\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, num_hidden, num_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
    "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
    "        self.act = torch.nn.GELU()\n",
    "    def forward(self, h_V):\n",
    "        h = self.act(self.W_in(h_V))\n",
    "        h = self.W_out(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class EncLayer(nn.Module):\n",
    "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
    "        super(EncLayer, self).__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_in = num_in\n",
    "        self.scale = scale\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(num_hidden)\n",
    "        self.norm2 = nn.LayerNorm(num_hidden)\n",
    "        self.norm3 = nn.LayerNorm(num_hidden)\n",
    "\n",
    "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
    "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
    "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.act = torch.nn.GELU()\n",
    "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
    "\n",
    "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
    "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
    "\n",
    "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx) # get neighbers' node feature [B,N,K,C1] and add them to edge feature [B,N,K,c2] ->[B, N, K, C1+c2]\n",
    "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1) # [B,N,C] 2 [B, N, 1, C] 2 [B, N, K, C]\n",
    "        h_EV = torch.cat([h_V_expand, h_EV], -1) # concat self node feature with neighours' node&edge feature  -> [B, N, K, C1+C2+C3]\n",
    "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV))))) # 3 layers of MLP to generate message\n",
    "        if mask_attend is not None:\n",
    "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
    "        dh = torch.sum(h_message, -2) / self.scale # sum over K (neighour dimension) then scale-> aggregate message\n",
    "        h_V = self.norm1(h_V + self.dropout1(dh)) # update h_V with aggragate message\n",
    "\n",
    "        dh = self.dense(h_V) # add h_V to new MLP to generate new message\n",
    "        h_V = self.norm2(h_V + self.dropout2(dh)) # add residual and normalize to get final h_V\n",
    "        if mask_V is not None:\n",
    "            mask_V = mask_V.unsqueeze(-1)\n",
    "            h_V = mask_V * h_V\n",
    "\n",
    "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)  # get neighbers' new node feature [B,N,K,C] and add them to edge feature [B,N,K,c]\n",
    "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
    "        h_EV = torch.cat([h_V_expand, h_EV], -1) # [B, N, K, C1+c2+c3]\n",
    "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV))))) # 3 layer of MLP to generate new edge feature\n",
    "        h_E = self.norm3(h_E + self.dropout3(h_message)) # add residual  then norm to get final h_E\n",
    "        return h_V, h_E   # return updated h_V, h_E afte one round of message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 44, 16])\n",
      "torch.Size([2, 44, 30, 16])\n"
     ]
    }
   ],
   "source": [
    "#h_EV C1+C2+c3=16*3\n",
    "device='cuda'\n",
    "num_hidden, num_in=16, 32\n",
    "test = EncLayer(num_hidden=num_hidden, num_in=num_in).to(device)\n",
    "h_V, h_E=test.forward (h_V, h_E, E_idx, mask, mask_attend)\n",
    "print(h_V.shape)\n",
    "print(h_E.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode layer\n",
    "updated h_V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 44])\n"
     ]
    }
   ],
   "source": [
    "print(S.shape) # N,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x44 and 21x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m sequence_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m21\u001b[39m  \u001b[38;5;66;03m# One-hot for AA\u001b[39;00m\n\u001b[1;32m      3\u001b[0m W_s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(sequence_features, hidden_dim, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m h_S \u001b[38;5;241m=\u001b[39m \u001b[43mW_s\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(h_S\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# N, C\u001b[39;00m\n\u001b[1;32m      6\u001b[0m h_ES \u001b[38;5;241m=\u001b[39m cat_neighbors_nodes(h_S, h_E, E_idx)  \u001b[38;5;66;03m#gather neighours' seq feature add to h_E\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x44 and 21x16)"
     ]
    }
   ],
   "source": [
    "# Concatenate sequence embeddings for autoregressive decoder\n",
    "sequence_features=21  # One-hot for AA\n",
    "W_s = torch.nn.Linear(sequence_features, hidden_dim, bias=True).to(device)\n",
    "h_S = W_s(S.float())   # N, L, hidden\n",
    "print(h_S.shape) # N, L, hidden\n",
    "h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)  #gather neighours' seq feature add to h_E\n",
    "print(h_ES.shape)\n",
    "# Build encoder embeddings  initialize X with 0\n",
    "h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
    "h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder layer\n",
    "\n",
    "class DecLayer(nn.Module):\n",
    "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
    "        super(DecLayer, self).__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_in = num_in\n",
    "        self.scale = scale\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(num_hidden)\n",
    "        self.norm2 = nn.LayerNorm(num_hidden)\n",
    "\n",
    "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
    "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.act = torch.nn.GELU()\n",
    "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
    "\n",
    "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
    "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
    "\n",
    "        # Concatenate h_V_i to h_E_ij\n",
    "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1)\n",
    "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
    "\n",
    "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
    "        if mask_attend is not None:\n",
    "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
    "        dh = torch.sum(h_message, -2) / self.scale\n",
    "\n",
    "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
    "\n",
    "        # Position-wise feedforward\n",
    "        dh = self.dense(h_V)\n",
    "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
    "\n",
    "        if mask_V is not None:\n",
    "            mask_V = mask_V.unsqueeze(-1)\n",
    "            h_V = mask_V * h_V\n",
    "        return h_V "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch(env)",
   "language": "python",
   "name": "pytroch_kern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
