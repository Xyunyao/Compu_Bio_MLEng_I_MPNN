{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build_GNN_2: message passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from MPNN_featurize import featurize\n",
    "from build_GNN_1 import ProteinFeatures, gather_edges, PositionalEncodings\n",
    "\n",
    "batch = [\n",
    "    {\n",
    "        'seq_chain_A': 'MKLVFLVLLVFVQGF',\n",
    "        'coords_chain_A': {'N_chain_A': np.random.rand(15, 3), 'CA_chain_A': np.random.rand(15, 3), 'C_chain_A': np.random.rand(15, 3), 'O_chain_A': np.random.rand(15, 3)},\n",
    "        'seq_chain_B': 'MSVKVEEVG',\n",
    "        'coords_chain_B': {'N_chain_B': np.random.rand(9, 3), 'CA_chain_B': np.random.rand(9, 3), 'C_chain_B': np.random.rand(9, 3), 'O_chain_B': np.random.rand(9, 3)},\n",
    "        'seq_chain_C': 'ATCGATCGATCGATCG',\n",
    "        'coords_chain_C': {'N_chain_C': np.random.rand(16, 3), 'CA_chain_C': np.random.rand(16, 3), 'C_chain_C': np.random.rand(16, 3), 'O_chain_C': np.random.rand(16, 3)},\n",
    "        'masked_list': ['A', 'B'],\n",
    "        'visible_list': ['C'],\n",
    "        'num_of_chains': 3,\n",
    "        'seq': 'MKLVFLVLLVFVQGF'+ 'MSVKVEEVG' + 'ATCGATCGATCGATCG'\n",
    "    },\n",
    "      {\n",
    "        'seq_chain_X': 'ACDEFGHIKLMNPQRSTVWY',\n",
    "        'coords_chain_X': {'N_chain_X': np.random.rand(20, 3), 'CA_chain_X': np.random.rand(20, 3), 'C_chain_X': np.random.rand(20, 3), 'O_chain_X': np.random.rand(20, 3)},\n",
    "        'seq_chain_Y': 'ACCDEFGHILKLM',\n",
    "        'coords_chain_Y': {'N_chain_Y': np.random.rand(13, 3), 'CA_chain_Y': np.random.rand(13, 3), 'C_chain_Y': np.random.rand(13, 3), 'O_chain_Y': np.random.rand(13, 3)},\n",
    "        'seq_chain_Z': 'LKLMNRPQRST',\n",
    "        'coords_chain_Z': {'N_chain_Z': np.random.rand(11, 3), 'CA_chain_Z': np.random.rand(11, 3), 'C_chain_Z': np.random.rand(11, 3), 'O_chain_Z': np.random.rand(11, 3)},\n",
    "        'masked_list': ['X', 'Y'],\n",
    "        'visible_list': ['Z'],\n",
    "        'num_of_chains': 3,\n",
    "        'seq': 'ACDEFGHIKLMNPQRSTVWY'+'ACCDEFGHILKLM'+'LKLMNRPQRST'\n",
    "\n",
    "    }\n",
    "]\n",
    "device='cuda'\n",
    "X, S, mask, lengths, chain_M, residue_idx, mask_self, chain_encoding_all = featurize(batch, device)\n",
    "demo = ProteinFeatures(\n",
    "    edge_features=16, node_features=16, num_positional_embeddings=16,\n",
    "    num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16\n",
    ").to(device)\n",
    "E, E_idx=demo.forward(X,chain_M, residue_idx, chain_encoding_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize h_V with zero match h_E dim\n",
    "import torch\n",
    "h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
    "# MLP of h_E, we omit it here\n",
    "edge_features=E.shape[-1],\n",
    "hidden_dim=16\n",
    "W_e = torch.nn.Linear(edge_features, hidden_dim, bias=True).to(device)\n",
    "h_E = W_e(E)\n",
    "print(h_E.shape)\n",
    "\n",
    "# mask  [B, L, L]\n",
    "def gather_nodes(nodes, neighbor_idx):\n",
    "    # Features [B,L,C] at Neighbor indices [B,L,K] => [B,N,K,C]\n",
    "    # Flatten and expand indices per batch [B,L,K] => [B,LK] => [B,NK,C]\n",
    "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1)) # [B, LK]\n",
    "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2)) #[B,Lk,1]->[b,lk,l]\n",
    "    # Gather and re-pack\n",
    "    # nodes [B,L,L,1]\n",
    "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
    "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
    "    return neighbor_features\n",
    "\n",
    "# Encoder is unmasked self-attention\n",
    "mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1) # [B,L,K]\n",
    "mask_attend = mask.unsqueeze(-1) * mask_attend\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch(env)",
   "language": "python",
   "name": "pytroch_kern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
