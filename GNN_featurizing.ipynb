{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building GNN_1\n",
    "## feature representation \n",
    "Inputs: X, S, mask, lengths, chain_M, residue_idx, mask_self, chain_encoding_all\n",
    "\n",
    "node: CA atoms <br>\n",
    "edge E_idx  : topk shortest distance based on CA-CA distance <br>\n",
    "node_feature: h_V <br>\n",
    "edge_feature: h_E, containing physical distance(rbf_size * # of pairs of [N, CA, C, O, <br>CB] ) and relative residue number <br>\n",
    "masking: two type of masking for padding (based on chain_M), masking inter or intra <br>chains(based on chain_encoding_list)<br>\n",
    "\n",
    "outputs: E_idx, h_E<br>\n",
    "Next step:\n",
    "h_V (initialize with zero) and h_E is used in GNN and through message passing to update h_E and h_V<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we used output from featurize function\n",
    "#example data\n",
    "import numpy as np\n",
    "from MPNN_featurize import featurize\n",
    "\n",
    "batch = [\n",
    "    {\n",
    "        'seq_chain_A': 'MKLVFLVLLVFVQGF',\n",
    "        'coords_chain_A': {'N_chain_A': np.random.rand(15, 3), 'CA_chain_A': np.random.rand(15, 3), 'C_chain_A': np.random.rand(15, 3), 'O_chain_A': np.random.rand(15, 3)},\n",
    "        'seq_chain_B': 'MSVKVEEVG',\n",
    "        'coords_chain_B': {'N_chain_B': np.random.rand(9, 3), 'CA_chain_B': np.random.rand(9, 3), 'C_chain_B': np.random.rand(9, 3), 'O_chain_B': np.random.rand(9, 3)},\n",
    "        'seq_chain_C': 'ATCGATCGATCGATCG',\n",
    "        'coords_chain_C': {'N_chain_C': np.random.rand(16, 3), 'CA_chain_C': np.random.rand(16, 3), 'C_chain_C': np.random.rand(16, 3), 'O_chain_C': np.random.rand(16, 3)},\n",
    "        'masked_list': ['A', 'B'],\n",
    "        'visible_list': ['C'],\n",
    "        'num_of_chains': 3,\n",
    "        'seq': 'MKLVFLVLLVFVQGF'+ 'MSVKVEEVG' + 'ATCGATCGATCGATCG'\n",
    "    },\n",
    "      {\n",
    "        'seq_chain_X': 'ACDEFGHIKLMNPQRSTVWY',\n",
    "        'coords_chain_X': {'N_chain_X': np.random.rand(20, 3), 'CA_chain_X': np.random.rand(20, 3), 'C_chain_X': np.random.rand(20, 3), 'O_chain_X': np.random.rand(20, 3)},\n",
    "        'seq_chain_Y': 'ACCDEFGHILKLM',\n",
    "        'coords_chain_Y': {'N_chain_Y': np.random.rand(13, 3), 'CA_chain_Y': np.random.rand(13, 3), 'C_chain_Y': np.random.rand(13, 3), 'O_chain_Y': np.random.rand(13, 3)},\n",
    "        'seq_chain_Z': 'LKLMNRPQRST',\n",
    "        'coords_chain_Z': {'N_chain_Z': np.random.rand(11, 3), 'CA_chain_Z': np.random.rand(11, 3), 'C_chain_Z': np.random.rand(11, 3), 'O_chain_Z': np.random.rand(11, 3)},\n",
    "        'masked_list': ['X', 'Y'],\n",
    "        'visible_list': ['Z'],\n",
    "        'num_of_chains': 3,\n",
    "        'seq': 'ACDEFGHIKLMNPQRSTVWY'+'ACCDEFGHILKLM'+'LKLMNRPQRST'\n",
    "\n",
    "    }\n",
    "]\n",
    "device='cuda'\n",
    "X, S, mask, lengths, chain_M, residue_idx, mask_self, chain_encoding_all = featurize(batch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting build_GNN_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile build_GNN_1.py\n",
    "# orignail code\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncodings(nn.Module):\n",
    "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
    "        super(PositionalEncodings, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.max_relative_feature = max_relative_feature\n",
    "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
    "\n",
    "    def forward(self, offset, mask):\n",
    "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
    "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
    "        E = self.linear(d_onehot.float())\n",
    "        return E\n",
    "    \n",
    "def gather_edges(edges, neighbor_idx):\n",
    "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n",
    "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
    "    edge_features = torch.gather(edges, 2, neighbors)\n",
    "    return edge_features\n",
    "\n",
    "class ProteinFeatures(nn.Module):\n",
    "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
    "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
    "        \"\"\" Extract protein features \"\"\"\n",
    "        super(ProteinFeatures, self).__init__()\n",
    "        self.edge_features = edge_features\n",
    "        self.node_features = node_features\n",
    "        self.top_k = top_k\n",
    "        self.augment_eps = augment_eps \n",
    "        self.num_rbf = num_rbf\n",
    "        self.num_positional_embeddings = num_positional_embeddings\n",
    "\n",
    "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
    "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
    "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
    "        self.norm_edges = nn.LayerNorm(edge_features)\n",
    "\n",
    "    def _dist(self, X, mask, eps=1E-6):\n",
    "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
    "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
    "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
    "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
    "        D_adjust = D + (1. - mask_2D) * D_max\n",
    "        sampled_top_k = self.top_k\n",
    "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
    "        return D_neighbors, E_idx\n",
    "\n",
    "    def _rbf(self, D):\n",
    "        device = D.device\n",
    "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
    "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
    "        D_mu = D_mu.view([1,1,1,-1])\n",
    "        D_sigma = (D_max - D_min) / D_count\n",
    "        D_expand = torch.unsqueeze(D, -1)\n",
    "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
    "        return RBF\n",
    "\n",
    "    def _get_rbf(self, A, B, E_idx):\n",
    "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
    "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
    "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
    "        return RBF_A_B\n",
    "\n",
    "    def forward(self, X, mask, residue_idx, chain_labels):\n",
    "        if self.training and self.augment_eps > 0:\n",
    "            X = X + self.augment_eps * torch.randn_like(X)\n",
    "        \n",
    "        b = X[:,:,1,:] - X[:,:,0,:]\n",
    "        c = X[:,:,2,:] - X[:,:,1,:]\n",
    "        a = torch.cross(b, c, dim=-1)\n",
    "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
    "        Ca = X[:,:,1,:]\n",
    "        N = X[:,:,0,:]\n",
    "        C = X[:,:,2,:]\n",
    "        O = X[:,:,3,:]\n",
    " \n",
    "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
    "\n",
    "        RBF_all = []\n",
    "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
    "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
    "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
    "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
    "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
    "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
    "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
    "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
    "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
    "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
    "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
    "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
    "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
    "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
    "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
    "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
    "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
    "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
    "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
    "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
    "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
    "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
    "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
    "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
    "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
    "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
    "\n",
    "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
    "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
    "\n",
    "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
    "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
    "        E_positional = self.embeddings(offset.long(), E_chains)\n",
    "        E = torch.cat((E_positional, RBF_all), -1)\n",
    "        E = self.edge_embedding(E)\n",
    "        E = self.norm_edges(E)\n",
    "        return E, E_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breaddown of functions\n",
    "Class ProteinFeatures(nn.Module):\n",
    "    - Initialize with parameters:\n",
    "        edge_features, node_features\n",
    "        num_positional_embeddings (default: 16)\n",
    "        num_rbf (default: 16)\n",
    "        top_k (default: 30)\n",
    "        augment_eps (default: 0.0)\n",
    "        num_chain_embeddings (default: 16)\n",
    "\n",
    "    - Call the parent class initializer (super).\n",
    "    - Define instance variables for input parameters.\n",
    "    - Initialize:\n",
    "        - PositionalEncodings for positional embeddings.\n",
    "        - Linear transformation for edge features.\n",
    "        - Layer normalization for edges.\n",
    "\n",
    "Methods:\n",
    "\n",
    "1. `_dist(X, mask, eps=1e-6)`:\n",
    "    - Create a 2D mask for pairwise distance computation.\n",
    "    - Compute pairwise distances (D) between coordinates in X using the mask.\n",
    "    - Adjust distances for masked regions.\n",
    "    - Identify the top-k nearest neighbors for each point.\n",
    "    - Return the distances and indices of the top-k neighbors.\n",
    "\n",
    "2. `_rbf(D)`:\n",
    "    - Define radial basis function (RBF) parameters (min, max, count).\n",
    "    - Compute RBF expansion of distances D.\n",
    "    - Return the RBF representation.\n",
    "\n",
    "3. `_get_rbf(A, B, E_idx)`:\n",
    "    - Compute pairwise distances between points in A and B.\n",
    "    - Gather distances for top-k neighbors using E_idx.\n",
    "    - Convert distances to RBF representation.\n",
    "    - Return the RBF representation.\n",
    "\n",
    "4. `forward(X, mask, residue_idx, chain_labels)`:\n",
    "    - If in training mode and `augment_eps` > 0:\n",
    "        - Add random noise to the input coordinates (X).\n",
    "    - Extract atom positions (N, Ca, C, O, Cb) for the protein backbone.\n",
    "    - Compute pairwise distances and top-k indices using `_dist`.\n",
    "    - Generate RBF features for:\n",
    "        - Intra-atom pairs (Ca-Ca, N-N, etc.).\n",
    "        - Inter-atom pairs (Ca-N, Ca-C, etc.).\n",
    "    - Concatenate all RBF features.\n",
    "    - Compute positional offsets using residue indices and chain labels.\n",
    "    - Identify self vs. non-self interactions based on chain labels.\n",
    "    - Create edge features by combining positional embeddings and RBF features.\n",
    "    - Apply edge embedding and normalization.\n",
    "    - Return edge features and indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0010, 0.1319, 0.1947, 0.2920, 0.3160, 0.3528, 0.3663, 0.3675, 0.3915,\n",
      "        0.4363, 0.4774, 0.4821, 0.5453, 0.5860, 0.5929, 0.6301, 0.6304, 0.6589,\n",
      "        0.6782, 0.7061, 0.7180, 0.7350, 0.7607, 0.7616, 0.7640, 0.7864, 0.7878,\n",
      "        0.7886, 0.7932, 0.7976], device='cuda:0')\n",
      "tensor([ 0, 17,  1, 37, 23,  5, 28, 13,  7, 11, 36, 12, 14, 29, 18,  2, 15, 34,\n",
      "        24, 35, 19, 22, 20, 33, 26, 27, 21,  9, 31,  3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# breakdwon \n",
    "# How X is used\n",
    "b = X[:,:,1,:] - X[:,:,0,:] # B L CA-N  vector   B L 3\n",
    "c = X[:,:,2,:] - X[:,:,1,:] # C-CA VECTOR       B L 3\n",
    "a = torch.cross(b, c, dim=-1) # orthorgnal to N-CA-C plane\n",
    "Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:] # calculate ghost CB\n",
    "Ca = X[:,:,1,:] # cooridnates for backbone\n",
    "N = X[:,:,0,:]\n",
    "C = X[:,:,2,:]\n",
    "O = X[:,:,3,:]\n",
    "\n",
    "demo=ProteinFeatures(edge_features=16, node_features=16, num_positional_embeddings=16,\n",
    "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16)\n",
    "# use CA as node get neighbor info\n",
    "D_neighbors, E_idx = demo._dist(Ca, mask) # mask to tell whether it is padding\n",
    "# def _dist(self, X, mask, eps=1E-6):\n",
    "#     mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2) # generate a 2D mask for padddign\n",
    "#     dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2) # calculate interresidue vector\n",
    "#     D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps) # calculate interresidue distance and filter with padding mask\n",
    "#     D_max, _ = torch.max(D, -1, keepdim=True) # get the largest distance\n",
    "#     D_adjust = D + (1. - mask_2D) * D_max # for between padding position using the larget distance\n",
    "#     sampled_top_k = self.top_k\n",
    "#     D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False) # select top_k shortest distance, and extract id\n",
    "#     return D_neighbors, E_idx  # return value and indices\n",
    "print(D_neighbors[0,0,:])\n",
    "print(E_idx[0,0,:])  # now we know neighours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 44, 44, 1])\n",
      "torch.Size([2, 44, 30, 1])\n",
      "torch.Size([2, 44, 30])\n"
     ]
    }
   ],
   "source": [
    "# all distance are coded with RBF kernel\n",
    "# CA-CA is easy as we know values D_neighbours\n",
    "# how to calcualte other atom-atom pair distance, following take N N as examaple\n",
    "# We know N cooridates : We could calculate all N N distance, then pick out neighours based on E_idx, or pick eighbour first calculate\n",
    "# the first approach is used, coded in _get_rbf\n",
    "A=N # B, L, 3\n",
    "B=N # B, L, 3\n",
    "D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
    "D_A_B=D_A_B[:,:,:,None] # B L L 1\n",
    "print(D_A_B.shape)\n",
    "neighbors = E_idx.unsqueeze(-1).expand(-1, -1, -1, D_A_B.size(-1)) # B, L, K, 1\n",
    "print(neighbors.shape)\n",
    "edge_features = torch.gather(D_A_B, 2, neighbors)[:,:,:,0]# B, L, K\n",
    "print(edge_features.shape) # values of N-N distance of neighbour nodes are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 44, 30, 16])\n"
     ]
    }
   ],
   "source": [
    "# rbf_kernel\n",
    "#[B,L,K]  to [B,L, K, num_rbf]\n",
    "NN_features=demo._rbf(edge_features) # distance to rbf faetures\n",
    "print(NN_features.shape)\n",
    "\n",
    "# all backbone atom (including cb) pairs rbf featurs are calculated and concat\n",
    "#RBF_all = torch.cat(tuple(RBF_all), dim=-1) # tuplue convert list to tuple to fix sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 44, 30])\n",
      "torch.Size([2, 44, 30])\n",
      "torch.Size([2, 44, 30, 42])\n"
     ]
    }
   ],
   "source": [
    "# Now we focus on residue index part in edge_feature\n",
    "offset = residue_idx[:,:,None]-residue_idx[:,None,:] # Broadcast to 2D # B, L, L\n",
    "offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K] get interresidue idex differnt for neighbors\n",
    "print(offset.shape)\n",
    "d_chains = ((chain_encoding_all[:, :, None] - chain_encoding_all[:,None,:])==0).long() #find self vs non-self interaction\n",
    "E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]  #get residue pairs are intra (1) or inter (0) used as mask\n",
    "print(E_chains.shape)\n",
    "# encode inter residue index distance using one-hot (from Alphafold)\n",
    "#define maxmimum index distance, anything beyond treated as maximum \n",
    "# then onehot vector is used as input for a layer of MLP, output as residue index distance feature\n",
    "# inmpletment in positionEncoding\n",
    "max_relative_feature = 20 # only look left and right 20 \n",
    "# inter chain is set to 2*maxium +1\n",
    "# warning: only d = maxium  means close, both 0 and 2*max_relative_feature are far\n",
    "# E_chains used as mask for intra or inter chain\n",
    "d = torch.clip(offset + max_relative_feature, 0, 2*max_relative_feature)*E_chains + (1-E_chains)*(2*max_relative_feature+1) # B, L, K\n",
    "d_onehot = torch.nn.functional.one_hot(d, 2*max_relative_feature+1+1) # B, L, K, 2*maxium +1\n",
    "print(d_onehot.shape)\n",
    "# then d_onehot is used for MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finally concat physical distance and residue index distance feature\n",
    " used for MLP and then norm feature\n",
    "E = torch.cat((E_positional, RBF_all), -1)\n",
    "E = self.edge_embedding(E)\n",
    "E = self.norm_edges(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E is the h_E features [B, L, K, 2*maxium +1]\n",
    "### initalize h_V with zero, match dimension with h_E\n",
    "h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device) \n",
    "### h_V and h_E is used in GNN for message pass to update h_V an h_E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch(env)",
   "language": "python",
   "name": "pytroch_kern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
